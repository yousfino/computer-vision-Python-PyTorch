{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Convolutional Neural Network from Scratch\n",
    "* 2 Convolution Layers (Followed by ReLU)\n",
    "* 2 Max Pooling Layers\n",
    "* 3 Fully Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F # provides activation functions and functions for tasks like pooling, normalization, and convolution layers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN architecture\n",
    "class CNN(nn.Module): # nn.Module is the base class for all neural network modules in PyTorch\n",
    " def __init__(self):\n",
    "  # initialize the class as a subclass of nn.Module\n",
    "  super(CNN, self).__init__()\n",
    "  \n",
    "  # first convolutional layer\n",
    "  self.conv1 = nn.Conv2d(3, 6, 5) # input channels = 3, output channels = 6, kernel size = 5 (5x5 filter)\n",
    "  \n",
    "  # first max pooling layer\n",
    "  self.pool1 = nn.MaxPool2d(2, 2) # kernel size = 2, stride = 2\n",
    "  \n",
    "  # second convolutional layer\n",
    "  self.conv2 = nn.Conv2d(6, 16, 5) # input channels = 6, output channels = 16, kernel size = 5 (5x5 filter)\n",
    "  \n",
    "  # second max pooling layer\n",
    "  self.pool2 = nn.MaxPool2d(2, 2) # kernel size = 2, stride = 2\n",
    "  \n",
    "  # 3 fully connected layers\n",
    "  # linear transformation from 16*5*5 to 120\n",
    "  self.fc1 = nn.Linear(16 * 5 * 5, 120) # flatten the input, 16*5*5 input features, 120 output features\n",
    "  \n",
    "  # linear transformation from 120 to 84-dimensional space\n",
    "  self.fc2 = nn.Linear(120, 84) # 120 input features, 84 output features\n",
    "  \n",
    "  # linear transformation from 84 to 10-dimensional space (output classes)\n",
    "  self.fc3 = nn.Linear(84, 10) # 84 input features, 10 output features (number of classes)\n",
    "  \n",
    " def forward(self, x): # defines how the data flows through the network\n",
    "  # operation 1: first convolutional layer with ReLU activation and max pooling\n",
    "  x = self.conv1(x)\n",
    "  x = F.relu(x) # used to overcome the overfitting and vanishing gradient and increase the performance, sets negative values to zero and keeps positive values as they are, introducing non-linearity to the model to learn complex patterns\n",
    "  x = self.pool1(x)\n",
    "  \n",
    "  # operation 2: second convolutional layer with ReLU activation and max pooling\n",
    "  x = self.conv2(x)\n",
    "  x = F.relu(x)\n",
    "  x = self.pool2(x)\n",
    "  \n",
    "  # operation 3: flatten the data for the fully connected layers\n",
    "  x = x.view(-1, 16 * 5 * 5) # flattening x into 1-D tensor while preserving the total number of elements\n",
    "  \n",
    "  # operation 4: first fully connected layer with ReLU activation\n",
    "  x = self.fc1(x)\n",
    "  x = F.relu(x)\n",
    "  \n",
    "  # operation 5: second fully connected layer with ReLU activation\n",
    "  x = self.fc2(x)\n",
    "  x = F.relu(x)\n",
    "  \n",
    "  # operation 6: output layer (fully connected) with raw scores for each class\n",
    "  x = self.fc3(x)\n",
    "  \n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create an instance of the CNN class\n",
    "model = CNN()\n",
    "print(model) # print the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 6, 28, 28]           456\n",
      "├─MaxPool2d: 1-2                         [-1, 6, 14, 14]           --\n",
      "├─Conv2d: 1-3                            [-1, 16, 10, 10]          2,416\n",
      "├─MaxPool2d: 1-4                         [-1, 16, 5, 5]            --\n",
      "├─Linear: 1-5                            [-1, 120]                 48,120\n",
      "├─Linear: 1-6                            [-1, 84]                  10,164\n",
      "├─Linear: 1-7                            [-1, 10]                  850\n",
      "==========================================================================================\n",
      "Total params: 62,006\n",
      "Trainable params: 62,006\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.65\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.30\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Conv2d: 1-1                            [-1, 6, 28, 28]           456\n",
       "├─MaxPool2d: 1-2                         [-1, 6, 14, 14]           --\n",
       "├─Conv2d: 1-3                            [-1, 16, 10, 10]          2,416\n",
       "├─MaxPool2d: 1-4                         [-1, 16, 5, 5]            --\n",
       "├─Linear: 1-5                            [-1, 120]                 48,120\n",
       "├─Linear: 1-6                            [-1, 84]                  10,164\n",
       "├─Linear: 1-7                            [-1, 10]                  850\n",
       "==========================================================================================\n",
       "Total params: 62,006\n",
       "Trainable params: 62,006\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.65\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.05\n",
       "Params size (MB): 0.24\n",
       "Estimated Total Size (MB): 0.30\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3, 32, 32)) # input shape: (3, 32, 32) - 3 channels, 32x32 image size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 Image Dataset and its Augmentation\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# define the data transform for data augmentation, used to artificially increase the size of the training dataset by applying random transformations to the input images\n",
    "# transforms mitigate overfitting and improve the generalization of the model\n",
    "transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomRotation(10),\n",
    "                                transforms.RandomResizedCrop(32, scale=(0.8, 1.0), ratio=(1.0, 1.0)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:35<00:00, 4739656.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "# train data\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2) # iterate over the training dataset in batches of 4, shuffle the data, and use 2 subprocesses for data loading\n",
    "\n",
    "# test data\n",
    "testdata = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "trainloader = DataLoader(testdata, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "# CIFAR-10 classes\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset length: 50000\n",
      "testset length: 10000\n"
     ]
    }
   ],
   "source": [
    "# print the lengths of the train and test datasets\n",
    "print(\"trainset length:\", len(trainset))\n",
    "print(\"testset length:\", len(testdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
